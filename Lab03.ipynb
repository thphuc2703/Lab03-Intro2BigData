{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 03 - Spark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information\n",
    "\n",
    "| Student name       | ID       |\n",
    "|--------------------|----------|\n",
    "| Nguyễn Thiên Phúc  | 20127681 |\n",
    "| Lê Nguyễn Nhật Phú | 20127275 |\n",
    "| Võ Hiền Hải Thuận  | 20127344 |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "**`Restart Kernel` and `Run all cells` before submitting on Moodle or your work will be counted as 0!**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark \n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import scipy\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"\").getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1**: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+------------+\n",
      "|prediction|indexedLabel|    features|\n",
      "+----------+------------+------------+\n",
      "|       1.0|         1.0|[172.0,11.0]|\n",
      "|       1.0|         1.0|[172.0,11.0]|\n",
      "|       1.0|         1.0|[172.0,11.0]|\n",
      "|       1.0|         1.0|[172.0,11.0]|\n",
      "|       1.0|         1.0|[172.0,11.0]|\n",
      "+----------+------------+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_893a7a7e40a5, depth=5, numNodes=25, numClasses=14, numFeatures=2\n",
      "Decision Tree - Test Accuracy = 0.995633\n",
      "Decision Tree - Test Error = 0.00436681\n",
      "The Confusion Matrix for Decision Tree Model is :\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [2 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [5 0 0 ... 0 0 0]]\n",
      "The precision score for Decision Tree Model is: 0.02972972972972973\n",
      "The recall score for Decision Tree Model is: 0.02972972972972973\n"
     ]
    }
   ],
   "source": [
    "from pyspark.python.pyspark.shell import spark\n",
    "\n",
    "data = spark.read.load(\"Absenteeism_at_work.csv\", format=\"csv\", header=True, delimiter=\",\")\n",
    "data = data.withColumn(\"MOA\", data[\"Month of absence\"] - 0).withColumn(\"label\", data['Height'] - 0). \\\n",
    "    withColumn(\"ROA\", data[\"Reason for absence\"] - 0). \\\n",
    "    withColumn(\"distance\", data[\"Distance from Residence to Work\"] - 0). \\\n",
    "    withColumn(\"BMI\", data[\"Body mass index\"] - 0)\n",
    "#data.show()\n",
    "\n",
    "assem = VectorAssembler(inputCols=[\"label\", \"distance\"], outputCol='features')\n",
    "data = assem.transform(data)\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "y_true = data.select(\"BMI\").rdd.flatMap(lambda x: x).collect()\n",
    "y_pred = data.select(\"ROA\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "confusionmatrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='micro')\n",
    "\n",
    "recall = recall_score(y_true, y_pred, average='micro')\n",
    "\n",
    "treeModel = model.stages[2]\n",
    "# summary only\n",
    "print(treeModel)\n",
    "print(\"Decision Tree - Test Accuracy = %g\" % (accuracy))\n",
    "print(\"Decision Tree - Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "print(\"The Confusion Matrix for Decision Tree Model is :\\n\" + str(confusionmatrix))\n",
    "\n",
    "print(\"The precision score for Decision Tree Model is: \" + str(precision))\n",
    "\n",
    "print(\"The recall score for Decision Tree Model is: \" + str(recall))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2**: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Test set accuracy = 0.061224489795918366\n",
      "The Confusion Matrix for Naive Bayes Model is :\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [2 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [5 0 0 ... 0 0 0]]\n",
      "The precision score for Naive Bayes Model is: 0.02972972972972973\n",
      "The recall score for Naive Bayes Model is: 0.02972972972972973\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# import numpy\n",
    "# Load training data\n",
    "from pyspark.ml.linalg import SparseVector\n",
    "# from pyspark.python.pyspark.shell import spark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "data = spark.read.load(\"Absenteeism_at_work.csv\", format=\"csv\", header=True, delimiter=\",\")\n",
    "data = data.withColumn(\"MOA\", data[\"Month of absence\"] - 0).withColumn(\"label\", data['Seasons'] - 0). \\\n",
    "    withColumn(\"ROA\", data[\"Reason for absence\"] - 0). \\\n",
    "    withColumn(\"distance\", data[\"Distance from Residence to Work\"] - 0). \\\n",
    "    withColumn(\"BMI\", data[\"Body mass index\"] - 0)\n",
    "\n",
    "assem = VectorAssembler(inputCols=[\"label\", \"MOA\"], outputCol='features')\n",
    "\n",
    "data = assem.transform(data)\n",
    "# Split the data into train and test\n",
    "splits = data.randomSplit([0.7, 0.3], 1000)\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "\n",
    "# train the model\n",
    "model = nb.fit(train)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "\n",
    "y_true = data.select(\"BMI\").rdd.flatMap(lambda x: x).collect()\n",
    "y_pred = data.select(\"ROA\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "confusionmatrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='micro')\n",
    "\n",
    "recall = recall_score(y_true, y_pred, average='micro')\n",
    "\n",
    "\n",
    "print(\"Naive Bayes - Test set accuracy = \" + str(accuracy))\n",
    "\n",
    "print(\"Naive Bayes - Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "print(\"The Confusion Matrix for Naive Bayes Model is :\\n\" + str(confusionmatrix))\n",
    "\n",
    "print(\"The precision score for Naive Bayes Model is: \" + str(precision))\n",
    "\n",
    "print(\"The recall score for Naive Bayes Model is: \" + str(recall))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3**: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+------------+\n",
      "|predictedLabel|label|    features|\n",
      "+--------------+-----+------------+\n",
      "|         235.0|235.0|[235.0,11.0]|\n",
      "|         235.0|235.0|[235.0,11.0]|\n",
      "|         235.0|235.0|[235.0,11.0]|\n",
      "|         235.0|235.0|[235.0,11.0]|\n",
      "|         235.0|235.0|[235.0,11.0]|\n",
      "+--------------+-----+------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "RandomForestClassificationModel: uid=RandomForestClassifier_b54c79322d5f, numTrees=10, numClasses=24, numFeatures=2\n",
      "Random Forest - Test Accuracy = 0.84689\n",
      "Random Forest - Test Error = 0.15311\n",
      "The Confusion Matrix for Random Forest Model is :\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [2 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [5 0 0 ... 0 0 0]]\n",
      "The precision score for Random Forest Model is: 0.02972972972972973\n",
      "The recall score for Random Forest Model is: 0.02972972972972973\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "data = spark.read.load(\"Absenteeism_at_work.csv\", format=\"csv\", header=True, delimiter=\",\")\n",
    "\n",
    "data = data.withColumn(\"MOA\", data[\"Month of absence\"] - 0).withColumn(\"label\", data['Transportation expense'] - 0). \\\n",
    "    withColumn(\"ROA\", data[\"Reason for absence\"] - 0). \\\n",
    "    withColumn(\"distance\", data[\"Distance from Residence to Work\"] - 0). \\\n",
    "    withColumn(\"BMI\", data[\"Body mass index\"] - 0)\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "\n",
    "assem = VectorAssembler(inputCols=[\"label\", \"distance\"], outputCol='features')\n",
    "\n",
    "data = assem.transform(data)\n",
    "\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "y_true = data.select(\"BMI\").rdd.flatMap(lambda x: x).collect()\n",
    "y_pred = data.select(\"ROA\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "confusionmatrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='micro')\n",
    "\n",
    "recall = recall_score(y_true, y_pred, average='micro')\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only\n",
    "print(\"Random Forest - Test Accuracy = %g\" % (accuracy))\n",
    "print(\"Random Forest - Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "print(\"The Confusion Matrix for Random Forest Model is :\\n\" + str(confusionmatrix))\n",
    "\n",
    "print(\"The precision score for Random Forest Model is: \" + str(precision))\n",
    "\n",
    "print(\"The recall score for Random Forest Model is: \" + str(recall))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**:\n",
    "\n",
    "**Dataset 1: Iris Dataset**\n",
    "\n",
    "Description: It includes three iris species with 50 samples each as well as some properties about each flower. One flower species is linearly separable from the other two, but the other two are not linearly separable from each other.\n",
    "\n",
    "Link  [Iris dataset](https://www.kaggle.com/datasets/uciml/iris)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset 2: Red Wine Dataset**\n",
    "\n",
    "Description: This datasets is related to red variants of the Portuguese \"Vinho Verde\" wine. For more details, consult the reference [Cortez et al., 2009]. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).\n",
    "\n",
    "Link  [Red wine dataset](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
