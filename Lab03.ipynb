{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 03 - Spark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information\n",
    "\n",
    "| Student name       | ID       |\n",
    "|--------------------|----------|\n",
    "| Nguyễn Thiên Phúc  | 20127681 |\n",
    "| Lê Nguyễn Nhật Phú | 20127275 |\n",
    "| Võ Hiền Hải Thuận  | 20127344 |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "**`Restart Kernel` and `Run all cells` before submitting on Moodle or your work will be counted as 0!**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 3.4.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022 23:13:41)\n",
      "Spark context Web UI available at http://Phuc-Nguyen:4040\n",
      "Spark context available as 'sc' (master = local[*], app id = local-1682397379570).\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import findspark \n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "import scipy\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"\").getOrCreate()\n",
    "from pyspark.python.pyspark.shell import spark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1**: Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+----------------+---------------+-------+----------------------+-------------------------------+------------+---+----------------------+----------+--------------------+---------+---+--------------+-------------+---+------+------+---------------+-------------------------+---+-----+----+--------+----+\n",
      "| ID|Reason for absence|Month of absence|Day of the week|Seasons|Transportation expense|Distance from Residence to Work|Service time|Age|Work load Average/day |Hit target|Disciplinary_failure|Education|Son|Social drinker|Social smoker|Pet|Weight|Height|Body mass index|Absenteeism_time_in_hours|MOA|label| ROA|distance| BMI|\n",
      "+---+------------------+----------------+---------------+-------+----------------------+-------------------------------+------------+---+----------------------+----------+--------------------+---------+---+--------------+-------------+---+------+------+---------------+-------------------------+---+-----+----+--------+----+\n",
      "| 11|                26|               7|              3|      1|                   289|                             36|          13| 33|               239.554|        97|                   0|        1|  2|             1|            0|  1|    90|   172|             30|                        4|7.0|172.0|26.0|    36.0|30.0|\n",
      "| 36|                 0|               7|              3|      1|                   118|                             13|          18| 50|               239.554|        97|                   1|        1|  1|             1|            0|  0|    98|   178|             31|                        0|7.0|178.0| 0.0|    13.0|31.0|\n",
      "|  3|                23|               7|              4|      1|                   179|                             51|          18| 38|               239.554|        97|                   0|        1|  0|             1|            0|  0|    89|   170|             31|                        2|7.0|170.0|23.0|    51.0|31.0|\n",
      "|  7|                 7|               7|              5|      1|                   279|                              5|          14| 39|               239.554|        97|                   0|        1|  2|             1|            1|  0|    68|   168|             24|                        4|7.0|168.0| 7.0|     5.0|24.0|\n",
      "| 11|                23|               7|              5|      1|                   289|                             36|          13| 33|               239.554|        97|                   0|        1|  2|             1|            0|  1|    90|   172|             30|                        2|7.0|172.0|23.0|    36.0|30.0|\n",
      "+---+------------------+----------------+---------------+-------+----------------------+-------------------------------+------------+---+----------------------+----------+--------------------+---------+---+--------------+-------------+---+------+------+---------------+-------------------------+---+-----+----+--------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.load(\"Absenteeism_at_work.csv\", format=\"csv\", header=True, delimiter=\",\")\n",
    "data = data.withColumn(\"MOA\", data[\"Month of absence\"] - 0).withColumn(\"label\", data['Height'] - 0). \\\n",
    "    withColumn(\"ROA\", data[\"Reason for absence\"] - 0). \\\n",
    "    withColumn(\"distance\", data[\"Distance from Residence to Work\"] - 0). \\\n",
    "    withColumn(\"BMI\", data[\"Body mass index\"] - 0)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assem = VectorAssembler(inputCols=[\"MOA\", \"distance\", \"ROA\", \"BMI\"], outputCol='features')\n",
    "data = assem.transform(data)\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       1.0|         1.0| [3.0,11.0,0.0,29.0]|\n",
      "|       1.0|         1.0|[8.0,11.0,19.0,29.0]|\n",
      "|       1.0|         1.0|[3.0,11.0,22.0,29.0]|\n",
      "|       1.0|         1.0|[5.0,11.0,22.0,29.0]|\n",
      "|       1.0|         1.0|[8.0,11.0,23.0,29.0]|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "y_true = data.select(\"BMI\").rdd.flatMap(lambda x: x).collect()\n",
    "y_pred = data.select(\"ROA\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_729dbeed43e3, depth=5, numNodes=27, numClasses=14, numFeatures=4\n",
      "Decision Tree - Test Accuracy = 0.817352\n",
      "Decision Tree - Test Error = 0.182648\n",
      "The Confusion Matrix for Decision Tree Model is :\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [2 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [5 0 0 ... 0 0 0]]\n",
      "The precision score for Decision Tree Model is: 0.02972972972972973\n",
      "The recall score for Decision Tree Model is: 0.02972972972972973\n"
     ]
    }
   ],
   "source": [
    "confusionmatrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='micro')\n",
    "\n",
    "recall = recall_score(y_true, y_pred, average='micro')\n",
    "\n",
    "treeModel = model.stages[2]\n",
    "# summary only\n",
    "print(treeModel)\n",
    "print(\"Decision Tree - Test Accuracy = %g\" % (accuracy))\n",
    "print(\"Decision Tree - Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "print(\"The Confusion Matrix for Decision Tree Model is :\\n\" + str(confusionmatrix))\n",
    "\n",
    "print(\"The precision score for Decision Tree Model is: \" + str(precision))\n",
    "\n",
    "print(\"The recall score for Decision Tree Model is: \" + str(recall))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2**: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Test set accuracy = 0.061224489795918366\n",
      "Naive Bayes - Test Error = 0.938776\n",
      "The Confusion Matrix for Naive Bayes Model is :\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [2 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [5 0 0 ... 0 0 0]]\n",
      "The precision score for Naive Bayes Model is: 0.02972972972972973\n",
      "The recall score for Naive Bayes Model is: 0.02972972972972973\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.load(\"Absenteeism_at_work.csv\", format=\"csv\", header=True, delimiter=\",\")\n",
    "data = data.withColumn(\"MOA\", data[\"Month of absence\"] - 0).withColumn(\"label\", data['Seasons'] - 0). \\\n",
    "    withColumn(\"ROA\", data[\"Reason for absence\"] - 0). \\\n",
    "    withColumn(\"distance\", data[\"Distance from Residence to Work\"] - 0). \\\n",
    "    withColumn(\"BMI\", data[\"Body mass index\"] - 0)\n",
    "\n",
    "assem = VectorAssembler(inputCols=[\"MOA\", \"distance\", \"ROA\", \"BMI\"], outputCol='features')\n",
    "\n",
    "data = assem.transform(data)\n",
    "# Split the data into train and test\n",
    "splits = data.randomSplit([0.7, 0.3], 1000)\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "\n",
    "# train the model\n",
    "model = nb.fit(train)\n",
    "\n",
    "# select example rows to display.\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# compute accuracy on the test set\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "\n",
    "y_true = data.select(\"BMI\").rdd.flatMap(lambda x: x).collect()\n",
    "y_pred = data.select(\"ROA\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "confusionmatrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='micro')\n",
    "\n",
    "recall = recall_score(y_true, y_pred, average='micro')\n",
    "\n",
    "\n",
    "print(\"Naive Bayes - Test set accuracy = \" + str(accuracy))\n",
    "\n",
    "print(\"Naive Bayes - Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "print(\"The Confusion Matrix for Naive Bayes Model is :\\n\" + str(confusionmatrix))\n",
    "\n",
    "print(\"The precision score for Naive Bayes Model is: \" + str(precision))\n",
    "\n",
    "print(\"The recall score for Naive Bayes Model is: \" + str(recall))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 3**: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+--------------------+\n",
      "|predictedLabel|label|            features|\n",
      "+--------------+-----+--------------------+\n",
      "|         235.0|235.0| [3.0,11.0,0.0,29.0]|\n",
      "|         235.0|235.0|[6.0,11.0,13.0,29.0]|\n",
      "|         235.0|235.0|[7.0,11.0,22.0,29.0]|\n",
      "|         235.0|235.0|[8.0,11.0,23.0,29.0]|\n",
      "|         235.0|235.0|[11.0,11.0,25.0,2...|\n",
      "+--------------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "RandomForestClassificationModel: uid=RandomForestClassifier_e35b4fe9b784, numTrees=10, numClasses=24, numFeatures=4\n",
      "Random Forest - Test Accuracy = 0.872807\n",
      "Random Forest - Test Error = 0.127193\n",
      "The Confusion Matrix for Random Forest Model is :\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [2 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [5 0 0 ... 0 0 0]]\n",
      "The precision score for Random Forest Model is: 0.02972972972972973\n",
      "The recall score for Random Forest Model is: 0.02972972972972973\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "data = spark.read.load(\"Absenteeism_at_work.csv\", format=\"csv\", header=True, delimiter=\",\")\n",
    "data = data.withColumn(\"MOA\", data[\"Month of absence\"] - 0).withColumn(\"label\", data['Transportation expense'] - 0). \\\n",
    "    withColumn(\"ROA\", data[\"Reason for absence\"] - 0). \\\n",
    "    withColumn(\"distance\", data[\"Distance from Residence to Work\"] - 0). \\\n",
    "    withColumn(\"BMI\", data[\"Body mass index\"] - 0)\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "\n",
    "assem = VectorAssembler(inputCols=[\"MOA\", \"distance\", \"ROA\", \"BMI\"], outputCol='features')\n",
    "\n",
    "data = assem.transform(data)\n",
    "\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "y_true = data.select(\"BMI\").rdd.flatMap(lambda x: x).collect()\n",
    "y_pred = data.select(\"ROA\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "confusionmatrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='micro')\n",
    "\n",
    "recall = recall_score(y_true, y_pred, average='micro')\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only\n",
    "print(\"Random Forest - Test Accuracy = %g\" % (accuracy))\n",
    "print(\"Random Forest - Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "print(\"The Confusion Matrix for Random Forest Model is :\\n\" + str(confusionmatrix))\n",
    "\n",
    "print(\"The precision score for Random Forest Model is: \" + str(precision))\n",
    "\n",
    "print(\"The recall score for Random Forest Model is: \" + str(recall))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**:\n",
    "\n",
    "**Dataset 1: Iris Dataset**\n",
    "\n",
    "Description: It includes three iris species with 50 samples each as well as some properties about each flower. One flower species is linearly separable from the other two, but the other two are not linearly separable from each other.\n",
    "\n",
    "Link  [Iris dataset](https://www.kaggle.com/datasets/uciml/iris)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset 2: Red Wine Dataset**\n",
    "\n",
    "Description: This datasets is related to red variants of the Portuguese \"Vinho Verde\" wine. For more details, consult the reference [Cortez et al., 2009]. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).\n",
    "\n",
    "Link  [Red wine dataset](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementation**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On Iris Dataset**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Random forest on Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "from pyspark.python.pyspark.shell import spark\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer, VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+-----------+----------+-----------+----------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|SepalLength|SepalWidth|PetalLength|PetalWidth|\n",
      "+---+-------------+------------+-------------+------------+-----------+-----------+----------+-----------+----------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|        5.1|       3.5|        1.4|       0.2|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|        4.9|       3.0|        1.4|       0.2|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|        4.7|       3.2|        1.3|       0.2|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|        4.6|       3.1|        1.5|       0.2|\n",
      "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|        5.0|       3.6|        1.4|       0.2|\n",
      "+---+-------------+------------+-------------+------------+-----------+-----------+----------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "data = spark.read.load(\"Iris.csv\", format=\"csv\", header=True, delimiter=\",\")\n",
    "\n",
    "data = data.withColumn(\"SepalLength\", data[\"SepalLengthCm\"] - 0).withColumn(\"SepalWidth\", data['SepalWidthCm'] - 0). \\\n",
    "    withColumn(\"PetalLength\", data[\"PetalLengthCm\"] - 0). \\\n",
    "    withColumn(\"PetalWidth\", data[\"PetalWidthCm\"] - 0)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+-----------+-----------+----------+-----------+----------+-----------------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|SepalLength|SepalWidth|PetalLength|PetalWidth|         features|\n",
      "+---+-------------+------------+-------------+------------+-----------+-----------+----------+-----------+----------+-----------------+\n",
      "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|        5.1|       3.5|        1.4|       0.2|[5.1,3.5,1.4,0.2]|\n",
      "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|        4.9|       3.0|        1.4|       0.2|[4.9,3.0,1.4,0.2]|\n",
      "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|        4.7|       3.2|        1.3|       0.2|[4.7,3.2,1.3,0.2]|\n",
      "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|        4.6|       3.1|        1.5|       0.2|[4.6,3.1,1.5,0.2]|\n",
      "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|        5.0|       3.6|        1.4|       0.2|[5.0,3.6,1.4,0.2]|\n",
      "+---+-------------+------------+-------------+------------+-----------+-----------+----------+-----------+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assem = VectorAssembler(inputCols=[\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"], outputCol='features')\n",
    "data = assem.transform(data)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"Species\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+------------+-------------+------------+--------------+-----------+----------+-----------+----------+-----------------+------------+-----------------+--------------------+--------------------+----------+--------------+\n",
      "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|       Species|SepalLength|SepalWidth|PetalLength|PetalWidth|         features|indexedLabel|  indexedFeatures|       rawPrediction|         probability|prediction|predictedLabel|\n",
      "+---+-------------+------------+-------------+------------+--------------+-----------+----------+-----------+----------+-----------------+------------+-----------------+--------------------+--------------------+----------+--------------+\n",
      "|102|          5.8|         2.7|          5.1|         1.9|Iris-virginica|        5.8|       2.7|        5.1|       1.9|[5.8,2.7,5.1,1.9]|         2.0|[5.8,2.7,5.1,1.9]|[0.0,4.1428571428...|[0.0,0.4142857142...|       2.0|Iris-virginica|\n",
      "|108|          7.3|         2.9|          6.3|         1.8|Iris-virginica|        7.3|       2.9|        6.3|       1.8|[7.3,2.9,6.3,1.8]|         2.0|[7.3,2.9,6.3,1.8]|      [0.0,0.0,10.0]|       [0.0,0.0,1.0]|       2.0|Iris-virginica|\n",
      "| 11|          5.4|         3.7|          1.5|         0.2|   Iris-setosa|        5.4|       3.7|        1.5|       0.2|[5.4,3.7,1.5,0.2]|         0.0|[5.4,3.7,1.5,0.2]|      [10.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|   Iris-setosa|\n",
      "|111|          6.5|         3.2|          5.1|         2.0|Iris-virginica|        6.5|       3.2|        5.1|       2.0|[6.5,3.2,5.1,2.0]|         2.0|[6.5,3.2,5.1,2.0]|       [0.0,1.0,9.0]|       [0.0,0.1,0.9]|       2.0|Iris-virginica|\n",
      "|113|          6.8|         3.0|          5.5|         2.1|Iris-virginica|        6.8|       3.0|        5.5|       2.1|[6.8,3.0,5.5,2.1]|         2.0|[6.8,3.0,5.5,2.1]|      [0.0,0.0,10.0]|       [0.0,0.0,1.0]|       2.0|Iris-virginica|\n",
      "+---+-------------+------------+-------------+------------+--------------+-----------+----------+-----------+----------+-----------------+------------+-----------------+--------------------+--------------------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "predictions.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get y_true and y_pred\n",
    "y_true = predictions.select(\"indexedLabel\").rdd.flatMap(lambda x: x).collect()\n",
    "y_pred = predictions.select(\"prediction\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassificationModel: uid=RandomForestClassifier_4df80740591c, numTrees=10, numClasses=3, numFeatures=4\n",
      "Random Forest - Test Accuracy = 0.979167\n",
      "Random Forest - Test Error = 0.0208333\n",
      "The Confusion Matrix for Random Forest Model is :\n",
      "[[14  0  0]\n",
      " [ 0 15  1]\n",
      " [ 0  0 18]]\n",
      "The precision score for Random Forest Model is: 0.9791666666666666\n",
      "The recall score for Random Forest Model is: 0.9791666666666666\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "confusionmatrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='micro')\n",
    "\n",
    "recall = recall_score(y_true, y_pred, average='micro')\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only\n",
    "print(\"Random Forest - Test Accuracy = %g\" % (accuracy))\n",
    "print(\"Random Forest - Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "print(\"The Confusion Matrix for Random Forest Model is :\\n\" + str(confusionmatrix))\n",
    "\n",
    "print(\"The precision score for Random Forest Model is: \" + str(precision))\n",
    "\n",
    "print(\"The recall score for Random Forest Model is: \" + str(recall))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Decision Tree on Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"Species\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")\n",
    "\n",
    "# Chain indexers and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, dt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get y_true and y_pred\n",
    "y_true = predictions.select(\"indexedLabel\").rdd.flatMap(lambda x: x).collect()\n",
    "y_pred = predictions.select(\"prediction\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_b81c98937932, depth=4, numNodes=13, numClasses=3, numFeatures=4\n",
      "Decision Tree - Test Accuracy = 0.924528\n",
      "Decision Tree - Test Error = 0.0754717\n",
      "The Confusion Matrix for Decision Tree Model is :\n",
      "[[18  0  0]\n",
      " [ 0 17  3]\n",
      " [ 0  1 14]]\n",
      "The precision score for Decision Tree Model is: 0.9245283018867925\n",
      "The recall score for Decision Tree Model is: 0.9245283018867925\n"
     ]
    }
   ],
   "source": [
    "confusionmatrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='micro')\n",
    "\n",
    "recall = recall_score(y_true, y_pred, average='micro')\n",
    "\n",
    "treeModel = model.stages[2]\n",
    "# summary only\n",
    "print(treeModel)\n",
    "print(\"Decision Tree - Test Accuracy = %g\" % (accuracy))\n",
    "print(\"Decision Tree - Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "print(\"The Confusion Matrix for Decision Tree Model is :\\n\" + str(confusionmatrix))\n",
    "\n",
    "print(\"The precision score for Decision Tree Model is: \" + str(precision))\n",
    "\n",
    "print(\"The recall score for Decision Tree Model is: \" + str(recall))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On Red Wine Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|fixed acidity|volatile acidity|citric acid|residual sugar|chlorides|free sulfur dioxide|total sulfur dioxide|density|  pH|sulphates|alcohol|quality|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "|          7.4|             0.7|        0.0|           1.9|    0.076|               11.0|                34.0| 0.9978|3.51|     0.56|    9.4|    5.0|\n",
      "|          7.8|            0.88|        0.0|           2.6|    0.098|               25.0|                67.0| 0.9968| 3.2|     0.68|    9.8|    5.0|\n",
      "|          7.8|            0.76|       0.04|           2.3|    0.092|               15.0|                54.0|  0.997|3.26|     0.65|    9.8|    5.0|\n",
      "|         11.2|            0.28|       0.56|           1.9|    0.075|               17.0|                60.0|  0.998|3.16|     0.58|    9.8|    6.0|\n",
      "|          7.4|             0.7|        0.0|           1.9|    0.076|               11.0|                34.0| 0.9978|3.51|     0.56|    9.4|    5.0|\n",
      "+-------------+----------------+-----------+--------------+---------+-------------------+--------------------+-------+----+---------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.load(\"winequality-red.csv\", format=\"csv\", header=True, delimiter=\";\")\n",
    "data = data.withColumn(\"fixed acidity\", data[\"fixed acidity\"] - 0).withColumn(\"volatile acidity\", data['volatile acidity'] - 0). \\\n",
    "    withColumn(\"citric acid\", data[\"citric acid\"] - 0). \\\n",
    "    withColumn(\"residual sugar\", data[\"residual sugar\"] - 0). \\\n",
    "    withColumn(\"chlorides\", data[\"chlorides\"] - 0). \\\n",
    "    withColumn(\"free sulfur dioxide\", data[\"free sulfur dioxide\"] - 0). \\\n",
    "    withColumn(\"total sulfur dioxide\", data[\"total sulfur dioxide\"] - 0). \\\n",
    "    withColumn(\"density\", data[\"density\"] - 0). \\\n",
    "    withColumn(\"pH\", data[\"pH\"] - 0). \\\n",
    "    withColumn(\"sulphates\", data[\"sulphates\"] - 0). \\\n",
    "    withColumn(\"alcohol\", data[\"alcohol\"] - 0). \\\n",
    "    withColumn(\"quality\", data[\"quality\"] - 0)\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fixed acidity: double (nullable = true)\n",
      " |-- volatile acidity: double (nullable = true)\n",
      " |-- citric acid: double (nullable = true)\n",
      " |-- residual sugar: double (nullable = true)\n",
      " |-- chlorides: double (nullable = true)\n",
      " |-- free sulfur dioxide: double (nullable = true)\n",
      " |-- total sulfur dioxide: double (nullable = true)\n",
      " |-- density: double (nullable = true)\n",
      " |-- pH: double (nullable = true)\n",
      " |-- sulphates: double (nullable = true)\n",
      " |-- alcohol: double (nullable = true)\n",
      " |-- quality: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "assem = VectorAssembler(inputCols=[\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\",\n",
    "                                    \"chlorides\", \"free sulfur dioxide\",\"total sulfur dioxide\", \"density\", \n",
    "                                    \"pH\", \"sulphates\", \"alcohol\"], outputCol='features')\n",
    "data = assem.transform(data)\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"quality\", outputCol=\"indexedLabel\").fit(data)\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=12).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(labelCol=\"quality\", featuresCol=\"features\")\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6295361470266028\n",
      "R2: 0.3432513421012249\n",
      "MSE: 0.39631576041310035\n"
     ]
    }
   ],
   "source": [
    "test_stats = lrModel.evaluate(testData)\n",
    "print(f\"RMSE: {test_stats.rootMeanSquaredError}\")\n",
    "print(f\"R2: {test_stats.r2}\")\n",
    "print(f\"MSE: {test_stats.meanSquaredError}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
